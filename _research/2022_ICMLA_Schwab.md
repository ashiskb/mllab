---
title: Trusted Neural Network (TNN);  Reversibility in Neural Networks for Inference Integrity Verification
category: reliability|explainability
photo: 2022_tnn.jpg
year: 2022
publisher: ICMLA
---

<img width="300" src="{{site.baseurl}}/images/research/{{page.photo}}" data-action="zoom">
**Abstract**
In this concept paper we explore the topic of Reversibility in Neural Networks leveraged for Network Integrity Verification and craft the original term Trusted Neural Network (TNN), paired with the API abstraction around it, to embrace the idea formally.  This newly proposed high-level generalizable TNN, model builds upon the Invertible Neural Network architecture, trained simultaneously in both forward and reverse directions.  This allows for the original system inputs to be compared with the ones reconstructed from the outputs in the reversed flow to assess the integrity of the end-to-end inference flow.  The outcome of that assessment is captured as an Integrity Score and exposed as TNN output.  Concrete implementation reflecting the needs of specific problem domains can be derived from this general approach and are demonstrated in the experiments. The model aspires to become a useful practice in drafting high level systems architectures which incorporate AI capabilities.




**Source Codes**
- Not yet available

**Collaborators**
- Malgorzata Schwab
- Ashis Kumer Biswas

**News / Achievements**
- **ICMLA** - accepted and presented at the International Conference on Machine Learning and Applications
April 21-22, 2022 in Boston, United States. [Details of the venue](https://waset.org/machine-learning-and-applications-conference-in-april-2022-in-boston)
